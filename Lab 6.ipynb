{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79121446",
   "metadata": {},
   "source": [
    "# Lab 6: Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f78b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as ds\n",
    "import pickle \n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "def load_names(file):\n",
    "    with open(file, 'rb') as fl:\n",
    "        batch = pickle.load(fl, encoding='latin1')\n",
    "    \n",
    "    label_names = batch['label_names']\n",
    "    return label_names\n",
    "\n",
    "def load_data(file):\n",
    "    with open(file, 'rb') as fl:\n",
    "        batch = pickle.load(fl, encoding='latin1')\n",
    "        \n",
    "    features = batch['data']\n",
    "    labels = batch['labels']\n",
    "    return features, labels\n",
    "\n",
    "batch1, label1 = load_data('data_batch_1')\n",
    "batch2, label2 = load_data('data_batch_2')\n",
    "batch3, label3 = load_data('data_batch_3')\n",
    "batch4, label4 = load_data('data_batch_4')\n",
    "batch5, label5 = load_data('data_batch_5')\n",
    "x_test, y_test = load_data('test_batch')\n",
    "label_names = load_names('batches.meta')\n",
    "\n",
    "#concatenating files \n",
    "x_train = np.concatenate([batch1, batch2, batch3, batch4, batch5], 0)\n",
    "y_train = np.concatenate([label1, label2, label3, label4, label5], 0)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a364c230",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f279c527",
   "metadata": {},
   "source": [
    "[1.5 points] Choose and explain what metric(s) you will use to evaluate your algorithmâ€™s performance. You should give a detailed argument for why this (these) metric(s) are appropriate on your data. That is, why is the metric appropriate for the task (e.g., in terms of the business case for the task). Please note: rarely is accuracy the best evaluation metric to use. Think deeply about an appropriate measure of performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47244344",
   "metadata": {},
   "source": [
    "[1.5 points] Choose the method you will use for dividing your data into training and testing (i.e., are you using Stratified 10-fold cross validation? Shuffle splits? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. Convince me that your cross validation method is a realistic mirroring of how an algorithm would be used in practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcdab94",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab3ac1e",
   "metadata": {},
   "source": [
    "[1.5 points]  Setup the training to use data expansion in Keras (also called data augmentation). Explain why the chosen data expansion techniques are appropriate for your dataset. You can use the keras ImageGenerator as a pre-processing step OR in the optimization loop. You can also use the Keras-cv augmenter (a separate package: https://keras.io/keras_cv/ Links to an external site.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e2a9e4",
   "metadata": {},
   "source": [
    "[2 points] Create a convolutional neural network to use on your data using Keras. Investigate at least two different convolutional network architectures (and investigate changing some parameters of each architecture such as the number of filters--at minimum have two variations of each network for a total of four models trained). Use the method of train/test splitting and evaluation metric that you argued for at the beginning of the lab. Visualize the performance of the training and validation sets per iteration (use the \"history\" parameter of Keras). Be sure that models converge. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba65a25c",
   "metadata": {},
   "source": [
    "[1.5 points] Visualize the final results of the CNNs and interpret/compare the performances. Use proper statistics as appropriate, especially for comparing models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212313e3",
   "metadata": {},
   "source": [
    "[1 points] Compare the performance of your convolutional network to a standard multi-layer perceptron (MLP) using the receiver operating characteristic and area under the curve. Use proper statistical comparison techniques.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185eb3bc",
   "metadata": {},
   "source": [
    "## Exceptional Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6845beb",
   "metadata": {},
   "source": [
    "Use transfer learning to pre-train the weights of your initial layers of your CNN. Compare the performance when using transfer learning to training without transfer learning (i.e., compare to your best model from above) in terms of classification performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f3138a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
